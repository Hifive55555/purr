{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 构建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 1, 50)        400         ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " input_1 (InputLayer)           [(None, 100)]        0           []                               \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 50)           0           ['embedding[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 150)          0           ['input_1[0][0]',                \n",
      "                                                                  'flatten[0][0]']                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 32768)        4947968     ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 128, 256)     0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " gru (GRU)                      (None, 128, 128)     148224      ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 128, 128)     0           ['gru[0][0]']                    \n",
      "                                                                                                  \n",
      " time_distributed (TimeDistribu  (None, 128, 14)     1806        ['dropout[0][0]']                \n",
      " ted)                                                                                             \n",
      "                                                                                                  \n",
      " lambda (Lambda)                (None, 128, 14)      0           ['time_distributed[0][0]']       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 5,098,398\n",
      "Trainable params: 5,098,398\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 128, 14)]    0           []                               \n",
      "                                                                                                  \n",
      " gru_1 (GRU)                    (None, 128, 64)      15360       ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " input_4 (InputLayer)           [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 128, 64)      0           ['gru_1[0][0]']                  \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, 1, 50)        400         ['input_4[0][0]']                \n",
      "                                                                                                  \n",
      " gru_2 (GRU)                    (None, 32)           9408        ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 50)           0           ['embedding_1[0][0]']            \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 82)           0           ['gru_2[0][0]',                  \n",
      "                                                                  'flatten_1[0][0]']              \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 1)            83          ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 8)            664         ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 25,915\n",
      "Trainable params: 0\n",
      "Non-trainable params: 25,915\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, GRU, Embedding, Concatenate, Reshape, TimeDistributed, Dropout, Flatten, Lambda\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import BinaryCrossentropy, SparseCategoricalCrossentropy\n",
    "\n",
    "# 超参数\n",
    "noise_dim = 100\n",
    "num_classes = 8  # 假设有10个类别\n",
    "max_seq_length = 128  # 最大序列长度\n",
    "feature_dim = 13  # 特征维度\n",
    "eos_token = feature_dim + 1  # EOS标记的索引\n",
    "\n",
    "# 生成器\n",
    "def build_generator():\n",
    "    noise_input = Input(shape=(noise_dim,))\n",
    "    label_input = Input(shape=(1,), dtype='int32')\n",
    "    \n",
    "    # 类别标签嵌入\n",
    "    label_embedding = Embedding(num_classes, 50)(label_input)\n",
    "    label_embedding = Flatten()(label_embedding)\n",
    "    \n",
    "    # 将噪声向量和嵌入后的标签连接\n",
    "    gen_input = Concatenate()([noise_input, label_embedding])\n",
    "    \n",
    "    # 使用全连接层扩展维度\n",
    "    x = Dense(256 * max_seq_length)(gen_input)\n",
    "    x = Reshape((max_seq_length, 256))(x)\n",
    "    \n",
    "    # 使用GRU生成时序数据\n",
    "    gru_output, final_state = GRU(128, return_sequences=True, return_state=True)(x)\n",
    "    gru_output = Dropout(0.3)(gru_output)\n",
    "\n",
    "    # 使用GRU的状态来预测终止标记\n",
    "    eos_prob = Dense(1, activation='sigmoid')(final_state)\n",
    "    \n",
    "    # 输出层\n",
    "    out = TimeDistributed(Dense(feature_dim + 1, activation=None))(gru_output)\n",
    "    out = Lambda(lambda x: tf.nn.softmax(x, axis=-1))(out)\n",
    "    \n",
    "    model = Model(inputs=[noise_input, label_input], outputs=[out, eos_prob], name='generator')\n",
    "    return model\n",
    "\n",
    "# 判别器\n",
    "def build_discriminator():\n",
    "    mfcc_input = Input(shape=(max_seq_length, eos_token))\n",
    "    label_input = Input(shape=(1,), dtype='int32')\n",
    "    \n",
    "    # 类别标签嵌入\n",
    "    label_embedding = Embedding(num_classes, 50)(label_input)\n",
    "    label_embedding = Flatten()(label_embedding)\n",
    "    \n",
    "    # 使用GRU处理时序数据\n",
    "    x = GRU(64, return_sequences=True)(mfcc_input)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = GRU(32)(x)\n",
    "    \n",
    "    # 将GRU输出和嵌入后的标签连接\n",
    "    x = Concatenate()([x, label_embedding])\n",
    "    \n",
    "    # 真伪判断\n",
    "    validity = Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    # 类别预测\n",
    "    label = Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs=[mfcc_input, label_input], outputs=[validity, label], name='discriminator')\n",
    "    return model\n",
    "\n",
    "# 实例化模型\n",
    "generator = build_generator()\n",
    "discriminator = build_discriminator()\n",
    "\n",
    "# 定义损失函数\n",
    "def acgan_loss(alpha=0.5):\n",
    "    # 初始化损失函数\n",
    "    bce = BinaryCrossentropy(from_logits=True)\n",
    "    sce = SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "    def loss(y_true, y_pred):\n",
    "        validity, label_pred = y_pred\n",
    "        y_true_validity, y_true_label = y_true\n",
    "        \n",
    "        # 计算真实性损失\n",
    "        loss_real = bce(y_true_validity, validity)\n",
    "        \n",
    "        # 计算辅助分类损失\n",
    "        loss_aux = sce(y_true_label, label_pred)\n",
    "        \n",
    "        # 总损失\n",
    "        return alpha * loss_real + (1 - alpha) * loss_aux\n",
    "    \n",
    "    return loss\n",
    "\n",
    "# 编译判别器\n",
    "discriminator.compile(optimizer=Adam(learning_rate=0.0002, beta_1=0.5),\n",
    "                      loss=acgan_loss(),\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "# 创建AC-GAN\n",
    "input_noise = Input(shape=(noise_dim,))\n",
    "input_label = Input(shape=(1,), dtype='int32')\n",
    "generated_mfcc = generator([input_noise, input_label])\n",
    "\n",
    "# 在训练生成器时冻结判别器\n",
    "discriminator.trainable = False\n",
    "validity, label_pred = discriminator([generated_mfcc, input_label])\n",
    "\n",
    "acgan = Model(inputs=[input_noise, input_label], outputs=[validity, label_pred])\n",
    "acgan.compile(optimizer=Adam(learning_rate=0.0002, beta_1=0.5), loss=['binary_crossentropy', 'sparse_categorical_crossentropy'])\n",
    "\n",
    "# 显示模型结构\n",
    "print(generator.summary())\n",
    "print(discriminator.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "def load_audio(file_path):\n",
    "    # 加载音频文件\n",
    "    y, sr = librosa.load(file_path)\n",
    "    return y, sr\n",
    "\n",
    "def extract_features(y, sr):\n",
    "    # 提取特征\n",
    "    n_fft = min(2048, len(y))\n",
    "    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13, n_fft=n_fft).T\n",
    "    return mfccs\n",
    "\n",
    "def preprocess_data(label_dir):\n",
    "    X, y = [], []\n",
    "    for label in os.listdir(label_dir):\n",
    "        for file_name in os.listdir(os.path.join(label_dir, label)):\n",
    "            audio, sr = load_audio(os.path.join(label_dir, label, file_name))\n",
    "            features = extract_features(audio, sr)\n",
    "            X.append(features)\n",
    "            y.append(label)\n",
    "    return X, y\n",
    "\n",
    "X, y = preprocess_data('kick_samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (530,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mmap\u001b[39m(cat_dict\u001b[38;5;241m.\u001b[39mget, y))\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# 准备数据\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m X \u001b[38;5;241m=\u001b[39m [\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m, np\u001b[38;5;241m.\u001b[39marray(y)]\n\u001b[0;32m     18\u001b[0m y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(y)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# 数据预处理\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# 对类别标签进行one-hot编码\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (530,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "cat_dict = {\n",
    "    \"Top\":          0,\n",
    "    \"Chest\":        1,\n",
    "    \"Signature\":    2,\n",
    "    \"Stadium\":      3,\n",
    "    \"Punchy\":       4,\n",
    "    \"808s\":         5,\n",
    "    \"Big\":          6,\n",
    "    \"Hardstyle\":    7,\n",
    "}\n",
    "\n",
    "y = list(map(cat_dict.get, y))\n",
    "y = np.array(y)\n",
    "\n",
    "# 数据预处理\n",
    "# 对类别标签进行one-hot编码\n",
    "y = to_categorical(y, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成随机噪声\n",
    "def generate_noise(batch_size):\n",
    "    return np.random.normal(0, 1, (batch_size, noise_dim))\n",
    "\n",
    "# 生成真实数据批次\n",
    "def generate_real_batch(batch_size):\n",
    "    idx = np.random.randint(0, X.shape[0], batch_size)\n",
    "    mfccs = X[idx]\n",
    "    labels = y[idx]\n",
    "    return mfccs, labels\n",
    "\n",
    "# 生成假数据批次\n",
    "def generate_fake_batch(batch_size, generator):\n",
    "    noise = generate_noise(batch_size)\n",
    "    labels = np.random.randint(0, num_classes, batch_size)\n",
    "    labels = to_categorical(labels, num_classes=num_classes)\n",
    "    generated_mfccs, eos_probs = generator.predict([noise, labels])\n",
    "    eos_indices = np.argmax(generated_mfccs == eos_token, axis=1)\n",
    "    eos_indices[eos_indices == 0] = max_seq_length  # 如果没有生成EOS，则使用最大长度\n",
    "    for i, eos_index in enumerate(eos_indices):\n",
    "        generated_mfccs[i, eos_index:] = 0  # 填充0来表示序列结束\n",
    "    return generated_mfccs, labels\n",
    "\n",
    "# 训练判别器\n",
    "def train_discriminator(discriminator, real_mfccs, real_labels, fake_mfccs, fake_labels):\n",
    "    # 真实样本标签\n",
    "    valid_y = np.ones((real_mfccs.shape[0], 1))\n",
    "    # 假样本标签\n",
    "    fake_y = np.zeros((fake_mfccs.shape[0], 1))\n",
    "    \n",
    "    # 训练判别器\n",
    "    d_loss_real = discriminator.train_on_batch([real_mfccs, real_labels], [valid_y, real_labels])\n",
    "    d_loss_fake = discriminator.train_on_batch([fake_mfccs, fake_labels], [fake_y, fake_labels])\n",
    "    d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "    return d_loss\n",
    "\n",
    "# 训练生成器\n",
    "def train_generator(acgan, batch_size):\n",
    "    noise = generate_noise(batch_size)\n",
    "    labels = np.random.randint(0, num_classes, batch_size)\n",
    "    labels = to_categorical(labels, num_classes=num_classes)\n",
    "    valid_y = np.ones((batch_size, 1))\n",
    "    \n",
    "    # 训练生成器\n",
    "    g_loss = acgan.train_on_batch([noise, labels], valid_y)\n",
    "    return g_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.optimizers import Adam\n",
    "from keras.losses import BinaryCrossentropy, SparseCategoricalCrossentropy\n",
    "# from keras.metrics import Mean\n",
    "\n",
    "# 超参数\n",
    "batch_size = 32\n",
    "epochs = 1000\n",
    "sample_interval = 100  # 每隔多少批次保存一次生成的样本\n",
    "n_critic = 5  # 每训练一轮生成器前先训练判别器的轮数\n",
    "\n",
    "# 损失函数\n",
    "bce_loss = BinaryCrossentropy()\n",
    "scce_loss = SparseCategoricalCrossentropy()\n",
    "\n",
    "# 主训练循环\n",
    "d_losses = []\n",
    "g_losses = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for _ in range(n_critic):\n",
    "        # 生成真实数据批次\n",
    "        real_mfccs, real_labels = generate_real_batch(batch_size)\n",
    "        # 生成假数据批次\n",
    "        fake_mfccs, fake_labels = generate_fake_batch(batch_size, generator)\n",
    "        # 训练判别器\n",
    "        d_loss = train_discriminator(discriminator, real_mfccs, real_labels, fake_mfccs, fake_labels)\n",
    "        \n",
    "    # 训练生成器\n",
    "    g_loss = train_generator(acgan, batch_size)\n",
    "    \n",
    "    # 记录损失\n",
    "    d_losses.append(d_loss)\n",
    "    g_losses.append(g_loss)\n",
    "    \n",
    "    # 打印进度\n",
    "    print(f\"{epoch+1}/{epochs} [D loss: {d_loss[0]}, acc: {100*d_loss[3]}] [G loss: {g_loss}]\")\n",
    "    \n",
    "    # 每隔一定批次保存生成的样本\n",
    "    if (epoch + 1) % sample_interval == 0:\n",
    "        # 保存生成器的权重\n",
    "        generator.save_weights('generator_weights.h5')\n",
    "        # 可以在这里添加代码来生成一些样本并保存它们"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
