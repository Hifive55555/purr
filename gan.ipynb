{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义一些超参数\n",
    "\n",
    "其中最大序列长度和采样率通过帧大小与帧位移计算得到可以处理的最大时间：\n",
    "$$t_{\\max}={256\\times512\\div22050}\\approx 6\\text{~s}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型超参数\n",
    "# noise_dim = 100\n",
    "num_classes = 8  # 8个类别\n",
    "max_seq_length = 256  # 最大序列长度（Mel变换后的帧数）\n",
    "hop_length = 512  # Mel 帧位移\n",
    "global_n_fft = 2048  # 帧大小\n",
    "gloabl_sr = 22050  # 默认降采样为 22050\n",
    "feature_dim = 128  # 特征维度\n",
    "# eos_token = feature_dim + 1  # EOS标记的索引\n",
    "eos_threshold = 0.9  # 判断为EOS的概率\n",
    "\n",
    "# 训练超参数\n",
    "batch_size = 32\n",
    "epochs = 1000\n",
    "sample_interval = 100  # 每隔多少批次保存一次生成的样本\n",
    "n_critic = 0.5  # 每训练一轮生成器前先训练判别器的轮数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据处理\n",
    "\n",
    "这一次我们提取特征频率维度为 128 的 **Mel 谱图特征**。该特征的具体提取方法如下：\n",
    "\n",
    "1. 预处理: 音频信号首先被分帧，并且通常会应用汉明窗等窗口函数来减少帧边缘的突变效应。\n",
    "2. 傅里叶变换: 对每一帧执行快速傅里叶变换 (FFT)，得到该帧的频谱。\n",
    "3. 功率谱: 计算 FFT 结果的幅度平方，得到功率谱。\n",
    "4. Mel 滤波器组: 将功率谱通过一组 Mel 滤波器组，这组滤波器在 Mel 频率尺度上均匀分布，从而将功率谱转换到 Mel 频率尺度上。\n",
    "5. 对数转换: 为了压缩动态范围并使数据更加平稳，通常会对每个滤波器输出的结果取对数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "def load_audio(file_path):\n",
    "    # 加载音频文件\n",
    "    y, sr = librosa.load(file_path)\n",
    "    return y, sr\n",
    "\n",
    "def extract_features(y, sr):\n",
    "    n_fft = n_fft = min(global_n_fft, len(y))\n",
    "    # 提取 log_Mel 谱图特征\n",
    "    mel_spectrogram = librosa.feature.melspectrogram(\n",
    "        y=y, sr=gloabl_sr, n_mels=feature_dim, n_fft=n_fft, hop_length=hop_length)\n",
    "    # 取对数\n",
    "    # log_mel_spectrogram = librosa.power_to_db(mel_spectrogram, ref=np.max)\n",
    "    return mel_spectrogram.T\n",
    "\n",
    "def preprocess_data(label_dir):\n",
    "    X, y = [], []\n",
    "    for label in os.listdir(label_dir):\n",
    "        for file_name in os.listdir(os.path.join(label_dir, label)):\n",
    "            audio, sr = load_audio(os.path.join(label_dir, label, file_name))\n",
    "            features = extract_features(audio, sr)\n",
    "            X.append(features)\n",
    "            y.append(label)\n",
    "    return X, y\n",
    "\n",
    "X, y = preprocess_data('kick_samples')\n",
    "\n",
    "cat_dict = {\n",
    "    \"Top\":          0,\n",
    "    \"Chest\":        1,\n",
    "    \"Signature\":    2,\n",
    "    \"Stadium\":      3,\n",
    "    \"Punchy\":       4,\n",
    "    \"808s\":         5,\n",
    "    \"Big\":          6,\n",
    "    \"Hardstyle\":    7,\n",
    "}\n",
    "\n",
    "y = list(map(cat_dict.get, y))\n",
    "y = np.array(y)\n",
    "# y_cal = to_categorical(y, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了之后的音频重建，下面我们定义一个归一化概率转音频的函数。\n",
    "\n",
    "原理如下：\n",
    "1. 模型输出 Normalized Mel $x_假$：\n",
    "   $$x_假=G(z|\\lambda)$$\n",
    "2. 反归一化，得到 Scaled Mel $s$：\n",
    "   $$s=x_假\\cdot(\\max_{\\rm dB}-\\min_{\\rm dB})+\\min_{\\rm dB}$$\n",
    "3. 从对数能量到线性能量：\n",
    "   $$l=10^{(s/10)}$$\n",
    "4. 从 Mel 频率到线性频率：在实践中，我们通常不直接从Mel谱图重建回原始音频，而是使用Mel谱图作为输入来估计线性频谱。这通常通过使用 Griffin-Lim 算法或基于深度学习的方法（如 WaveNet 或 Tacotron）来完成。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_dB_energy(generated_mels, ref_value=1.0, top_db=80.0):\n",
    "    # 将输出转换为 dB 能量\n",
    "    dB_energy = librosa.power_to_db(generated_mels, ref=ref_value, top_db=top_db)\n",
    "    return dB_energy\n",
    "\n",
    "def denormalize_and_convert_to_audio(mel_spectrogram, sr=22050, n_fft=2048, hop_length=512):\n",
    "    # 反归一化\n",
    "    max_db = 0.0\n",
    "    min_db = -80.0\n",
    "    scaled_mel = (mel_spectrogram * (max_db - min_db)) + min_db\n",
    "    \n",
    "    # 从对数能量到线性能量\n",
    "    linear_mel = librosa.db_to_power(scaled_mel)\n",
    "    \n",
    "    # 使用 Griffin-Lim 算法重建相位信息\n",
    "    audio_reconstructed = librosa.feature.inverse.mel_to_audio(linear_mel, sr=sr, n_fft=n_fft, hop_length=hop_length)\n",
    "    \n",
    "    return audio_reconstructed\n",
    "\n",
    "# 保存音频文件\n",
    "# librosa.output.write_wav('reconstructed_audio.wav', audio_reconstructed, sr=22050)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 构建模型\n",
    "\n",
    "#### 生成器\n",
    "\n",
    "- **输入**：一组 100 维的噪声数据；一组 1 维的标签数据（通过整数编码）\n",
    "- 标签嵌入：Embedding 层中第一个参数表示标签数量，第二个表示输出嵌入标签的维度。\n",
    "- 标签连接：噪声向量与嵌入标签连接，作为新的输入（通过特征轴连接）\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"generator\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " label_input (InputLayer)       [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " label_embedding (Embedding)    (None, 1, 50)        400         ['label_input[0][0]']            \n",
      "                                                                                                  \n",
      " flatten_3 (Flatten)            (None, 50)           0           ['label_embedding[0][0]']        \n",
      "                                                                                                  \n",
      " noise_input (InputLayer)       [(None, 256, 128)]   0           []                               \n",
      "                                                                                                  \n",
      " repeat_vector_3 (RepeatVector)  (None, 256, 50)     0           ['flatten_3[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate_9 (Concatenate)    (None, 256, 178)     0           ['noise_input[0][0]',            \n",
      "                                                                  'repeat_vector_3[0][0]']        \n",
      "                                                                                                  \n",
      " gru_generator_1 (GRU)          (None, 256, 256)     334848      ['concatenate_9[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)            (None, 256, 256)     0           ['gru_generator_1[0][0]']        \n",
      "                                                                                                  \n",
      " gru_generator_2 (GRU)          (None, 256, 256)     394752      ['dropout_6[0][0]']              \n",
      "                                                                                                  \n",
      " fake_output (TimeDistributed)  (None, 256, 128)     32896       ['gru_generator_2[0][0]']        \n",
      "                                                                                                  \n",
      " eos_output (TimeDistributed)   (None, 256, 1)       257         ['gru_generator_2[0][0]']        \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 763,153\n",
      "Trainable params: 762,753\n",
      "Non-trainable params: 400\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Model: \"discriminator\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " mel_input (InputLayer)         [(None, None, 128)]  0           []                               \n",
      "                                                                                                  \n",
      " eos_input (InputLayer)         [(None, None, 1)]    0           []                               \n",
      "                                                                                                  \n",
      " concatenate_10 (Concatenate)   (None, None, 129)    0           ['mel_input[0][0]',              \n",
      "                                                                  'eos_input[0][0]']              \n",
      "                                                                                                  \n",
      " gru_feature (GRU)              (None, None, 128)    99456       ['concatenate_10[0][0]']         \n",
      "                                                                                                  \n",
      " label_input (InputLayer)       [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)            (None, None, 128)    0           ['gru_feature[0][0]']            \n",
      "                                                                                                  \n",
      " label_embedding (Embedding)    (None, 1, 50)        400         ['label_input[0][0]']            \n",
      "                                                                                                  \n",
      " gru_category (GRU)             (None, 64)           37248       ['dropout_7[0][0]']              \n",
      "                                                                                                  \n",
      " flatten_3 (Flatten)            (None, 50)           0           ['label_embedding[0][0]']        \n",
      "                                                                                                  \n",
      " concatenate_11 (Concatenate)   (None, 114)          0           ['gru_category[0][0]',           \n",
      "                                                                  'flatten_3[0][0]']              \n",
      "                                                                                                  \n",
      " validity (Dense)               (None, 1)            115         ['concatenate_11[0][0]']         \n",
      "                                                                                                  \n",
      " label (Dense)                  (None, 8)            520         ['gru_category[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 137,739\n",
      "Trainable params: 0\n",
      "Non-trainable params: 137,739\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, GRU, Embedding, Concatenate, Reshape, TimeDistributed, Dropout, Flatten, RepeatVector\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import binary_crossentropy, categorical_crossentropy\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "\n",
    "# 共享的标签嵌入层\n",
    "label_embedding_layer = Embedding(num_classes, 50, name='label_embedding')\n",
    "flatten_layer = Flatten()\n",
    "\n",
    "# 创建标签输入\n",
    "label_input = Input(shape=(1), name='label_input')\n",
    "\n",
    "# 应用嵌入和展平操作\n",
    "label_embedding = label_embedding_layer(label_input)\n",
    "label_embedding = flatten_layer(label_embedding)\n",
    "\n",
    "# 生成器\n",
    "def build_generator():\n",
    "    noise_input = Input(shape=(max_seq_length,feature_dim), name='noise_input')\n",
    "\n",
    "    # 重复标签以匹配噪声序列的长度\n",
    "    repeated_label = RepeatVector(max_seq_length)(label_embedding)\n",
    "    \n",
    "    # 将标签与噪声序列连接\n",
    "    gen_input = Concatenate(axis=-1)([noise_input, repeated_label])\n",
    "\n",
    "    # 使用GRU生成时序数据\n",
    "    x = GRU(256, return_sequences=True, name='gru_generator_1')(gen_input)\n",
    "    x = Dropout(0.3)(x)\n",
    "    gru_output = GRU(256, return_sequences=True, name='gru_generator_2')(x)\n",
    "    \n",
    "    # 输出层\n",
    "    out = TimeDistributed(Dense(feature_dim, activation='relu'), name='fake_output')(gru_output)\n",
    "    eos_output = TimeDistributed(Dense(1, activation='sigmoid'), name='eos_output')(gru_output)\n",
    "    # out = Lambda(lambda x: tf.nn.softmax(x, axis=-1))(out)\n",
    "    \n",
    "    model = Model(inputs=[noise_input, label_input], outputs=[out, eos_output], name='generator')\n",
    "    return model\n",
    "\n",
    "# 判别器\n",
    "def build_discriminator():\n",
    "    mel_input = Input(shape=(None, feature_dim), name='mel_input')\n",
    "    eos_input = Input(shape=(None, 1), name='eos_input')\n",
    "    gen_input = Concatenate(axis=-1)([mel_input, eos_input])\n",
    "    \n",
    "    # 使用GRU处理时序数据\n",
    "    x = GRU(128, return_sequences=True, name='gru_feature')(gen_input)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = GRU(64, name='gru_category')(x)\n",
    "    \n",
    "    # 将GRU输出和嵌入后的标签连接\n",
    "    x_connected = Concatenate()([x, label_embedding])\n",
    "    \n",
    "    # 真伪判断\n",
    "    validity = Dense(1, activation='sigmoid', name='validity')(x_connected)\n",
    "    # 类别预测\n",
    "    label = Dense(num_classes, activation='softmax', name='label')(x)\n",
    "    \n",
    "    model = Model(inputs=[mel_input, label_input, eos_input], outputs=[validity, label], name='discriminator')\n",
    "    return model\n",
    "\n",
    "# 实例化模型\n",
    "generator = build_generator()\n",
    "discriminator = build_discriminator()\n",
    "\n",
    "\n",
    "# 编译判别器\n",
    "discriminator.compile(optimizer=Adam(learning_rate=0.0002, beta_1=0.5),\n",
    "                      loss=['binary_crossentropy', 'categorical_crossentropy'],\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "# 创建AC-GAN\n",
    "input_noise = Input(shape=(max_seq_length, feature_dim))\n",
    "input_label = Input(shape=(1,), dtype='int32')\n",
    "generated_mel, eos_output = generator([input_noise, input_label])\n",
    "# generated_mel = convert_to_dB_energy(generated_mel)\n",
    "\n",
    "# 在训练生成器时冻结判别器\n",
    "discriminator.trainable = False\n",
    "validity, label_pred = discriminator([generated_mel, input_label, eos_output])\n",
    "\n",
    "acgan = Model(inputs=[input_noise, input_label], outputs=[validity, label_pred], name='AC-GAN')\n",
    "acgan.compile(optimizer=Adam(learning_rate=0.002, beta_1=0.5),\n",
    "              loss=[lambda _, y_pred: binary_crossentropy(tf.ones_like(y_pred), y_pred), 'categorical_crossentropy'],\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 显示模型结构\n",
    "print(generator.summary())\n",
    "print(discriminator.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成随机噪声\n",
    "def generate_noise():\n",
    "    return np.random.normal(0, 1, (batch_size, max_seq_length, feature_dim))\n",
    "\n",
    "# 生成真实数据批次\n",
    "def generate_real_batch():\n",
    "    idxs = np.random.randint(0, len(X), batch_size)\n",
    "    mels = [X[idx] for idx in idxs]\n",
    "    labels = [y[idx] for idx in idxs]\n",
    "    eoss = [np.zeros((X[idx].shape[0],1)) for idx in idxs]\n",
    "    for eos in eoss:\n",
    "        eos[-1,0] = 1\n",
    "    return tf.ragged.constant(mels), tf.convert_to_tensor(labels), tf.ragged.constant(eoss)\n",
    "\n",
    "# 生成假数据批次\n",
    "def generate_fake_batch():\n",
    "    noise = generate_noise()\n",
    "    labels = np.random.randint(0, num_classes, batch_size)\n",
    "    labels = tf.convert_to_tensor(labels)\n",
    "    generated_mels, generated_eos = generator.predict([noise, labels])\n",
    "    # eos 去除\n",
    "    for i in range(generated_mels.shape[0]):\n",
    "        eos_indices = np.where(generated_eos[i] >= eos_threshold)[0]\n",
    "        if len(eos_indices) > 0:\n",
    "            eos_index = eos_indices[0]\n",
    "            try:\n",
    "                generated_mels[i] = generated_mels[i][i, :eos_index]\n",
    "            except:\n",
    "                pass\n",
    "    return generated_mels, labels, generated_eos\n",
    "\n",
    "# 训练判别器\n",
    "def train_discriminator(real_mels, real_labels, real_eoss, fake_mels, fake_labels, fake_eoss):\n",
    "    discriminator.trainable = True\n",
    "    generator.trainable = False\n",
    "\n",
    "    # 真假样本标签\n",
    "    valid_y = tf.ones((batch_size, 1))\n",
    "    fake_y = tf.zeros((batch_size, 1))\n",
    "\n",
    "    real_labels_categorical = to_categorical(real_labels, num_classes)\n",
    "    fake_labels_categorical = to_categorical(fake_labels, num_classes)\n",
    "\n",
    "    # 确保 real_labels_categorical 和 fake_labels_categorical 都是张量\n",
    "    real_labels_categorical = tf.convert_to_tensor(real_labels_categorical)\n",
    "    fake_labels_categorical = tf.convert_to_tensor(fake_labels_categorical)\n",
    "\n",
    "    # 训练判别器\n",
    "    d_loss_real = discriminator.train_on_batch(\n",
    "        [real_mels, real_labels, real_eoss],\n",
    "        [valid_y, real_labels_categorical])\n",
    "    d_loss_fake = discriminator.train_on_batch(\n",
    "        [fake_mels, fake_labels, fake_eoss],\n",
    "        [fake_y, fake_labels_categorical])\n",
    "    d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "    return d_loss\n",
    "\n",
    "# 训练生成器\n",
    "def train_generator():\n",
    "    discriminator.trainable = False\n",
    "    generator.trainable = True\n",
    "\n",
    "    noise = generate_noise()\n",
    "    labels = np.random.randint(0, num_classes, batch_size)\n",
    "    valid_y = np.ones((batch_size, 1))\n",
    "    \n",
    "    # 训练生成器\n",
    "    g_loss = acgan.train_on_batch([noise, labels], [valid_y, to_categorical(labels, num_classes)])\n",
    "    return g_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练的时候把损失绘制成图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########### 训练判别器 ###########\n",
      "1/1 [==============================] - 1s 1s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ProgramData\\anaconda3\\envs\\ML\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/discriminator/gru_category/RaggedToTensor/boolean_mask_1/GatherV2:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/discriminator/gru_category/RaggedToTensor/boolean_mask/GatherV2:0\", shape=(None, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/discriminator/gru_category/RaggedToTensor/Shape:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 主训练循环\n",
    "d_losses = []\n",
    "g_losses = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(\"########### 训练判别器 ###########\")\n",
    "    n = int(n_critic*20)\n",
    "    for _ in range(n):\n",
    "        # 生成真实数据批次\n",
    "        real_mels, real_labels, real_eoss = generate_real_batch()\n",
    "        # 生成假数据批次\n",
    "        fake_mels, fake_labels, fake_eoss = generate_fake_batch()\n",
    "        # 训练判别器\n",
    "        d_loss = train_discriminator(real_mels, real_labels, real_eoss, fake_mels, fake_labels, fake_eoss)\n",
    "    \n",
    "    print(\"训练生成器\")\n",
    "    # 训练生成器\n",
    "    for _ in range(10-n):\n",
    "        g_loss = train_generator()\n",
    "    \n",
    "    # 记录损失\n",
    "    d_losses.append(d_loss)\n",
    "    g_losses.append(g_loss)\n",
    "    n_critic = d_loss[0]/(d_loss[0]+g_loss[0])\n",
    "    if n_critic < 0.35:\n",
    "        n_critic = n_critic**2\n",
    "    print(n_critic)\n",
    "    \n",
    "    # 打印进度\n",
    "    print(f\"Epoch {epoch+1}/{epochs} [D loss: {d_loss[0]:.3f} - validity_loss: {d_loss[1]:.3f} - label_loss: {d_loss[2]:.3f}]\")\n",
    "    print(f\"Epoch {epoch+1}/{epochs} [G loss: {g_loss[0]:.3f} - validity_loss: {g_loss[1]:.3f} - label_loss: {g_loss[2]:.3f}]\")\n",
    "    \n",
    "    # 每隔一定批次保存生成的样本\n",
    "    if (epoch + 1) % sample_interval == 0:\n",
    "        # 保存生成器的权重\n",
    "        generator.save_weights('generator_weights_2.h5')\n",
    "        # 可以在这里添加代码来生成一些样本并保存它们\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "display.clear_output(wait=True)\n",
    "\n",
    "def update_plot(d_losses, g_losses):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.clf()  # 清除之前的图像\n",
    "    \n",
    "    # 绘制 D 损失\n",
    "    plt.plot(d_losses, label='D Loss', color='blue')\n",
    "    plt.plot(g_losses, label='G Loss', color='red')\n",
    "    \n",
    "    # 设置图表标题和标签\n",
    "    plt.title('Training Losses')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.show()  # 显示图表\n",
    "\n",
    "update_plot(d_losses, g_losses)\n",
    "plt.savefig('loss_3.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
