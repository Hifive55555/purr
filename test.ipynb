{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据处理与特征提取\n",
    "\n",
    "在 `kick_samples` 文件夹中有 8 个子目录，分别对于不同 kick 样本的类别。采用独热编码，编码为长度为 8 的向量。\n",
    "\n",
    "- 首先通过 `librosa` 加载音频文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-234.05597    203.531       49.927414  ...    7.677088     9.928037\n",
      "     6.722163 ]\n",
      " [-254.66223    199.44435     61.523598  ...   10.261335    10.4524975\n",
      "     9.955725 ]\n",
      " [-361.2908     132.92685     93.41626   ...   13.143988    12.698032\n",
      "    12.344129 ]\n",
      " ...\n",
      " [-464.18796      4.6727586    4.665011  ...    4.4217567    4.3697395\n",
      "     4.313256 ]\n",
      " [-465.8464       2.3291216    2.3266516 ...    2.2483687    2.2314472\n",
      "     2.212997 ]\n",
      " [-467.49396      0.           0.        ...    0.           0.\n",
      "     0.       ]]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def load_audio(file_path):\n",
    "    # 加载音频文件\n",
    "    y, sr = librosa.load(file_path, sr=16000)\n",
    "    return y, sr\n",
    "\n",
    "def extract_features(y, sr):\n",
    "    # 提取特征\n",
    "    n_fft = min(2048, len(y))\n",
    "    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13, n_fft=n_fft).T\n",
    "    return mfccs\n",
    "\n",
    "def preprocess_data(label_dir):\n",
    "    X, y = [], []\n",
    "    for label in os.listdir(label_dir):\n",
    "        for file_name in os.listdir(os.path.join(label_dir, label)):\n",
    "            audio, sr = load_audio(os.path.join(label_dir, label, file_name))\n",
    "            features = extract_features(audio, sr)\n",
    "            X.append(features)\n",
    "            y.append(label)\n",
    "    return X, y\n",
    "\n",
    "\n",
    "X, y = preprocess_data('kick_samples')\n",
    "print(X[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 构建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense, Dropout, Flatten\n",
    "\n",
    "def build_multi_task_model(input_shape, num_classes):\n",
    "    # 输入层\n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    # 共享特征提取层\n",
    "    lstm1 = LSTM(128, return_sequences=True)(inputs)\n",
    "    dropout1 = Dropout(0.5)(lstm1)\n",
    "    lstm2 = LSTM(64)(dropout1)\n",
    "    dropout2 = Dropout(0.5)(lstm2)\n",
    "\n",
    "    # 将 LSTM 输出展平，以便与 Dense 层连接\n",
    "    flattened = Flatten()(dropout2)\n",
    "    \n",
    "    # 时间预测分支\n",
    "    cat_output = Dense(num_classes, activation='softmax', name='cat')(flattened)\n",
    "    \n",
    "    # 构建模型\n",
    "    model = Model(inputs=inputs, outputs=cat_output)\n",
    "    \n",
    "    # 编译模型\n",
    "    model.compile(\n",
    "        loss={'cat': 'categorical_crossentropy'},\n",
    "        optimizer='adam',\n",
    "        metrics={'cat': 'accuracy'}\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# 假设每个任务的类别数\n",
    "num_classes = 14\n",
    "\n",
    "# 假设输入形状\n",
    "input_shape = (None, 13)  # 假设我们使用13维的MFCC特征\n",
    "\n",
    "# 构建模型\n",
    "model = build_multi_task_model(input_shape, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7, 11, 13, 10, 11, 3, 8, 11, 12, 1, 9, 12, 5, 6, 12, 1, 7, 12]\n",
      "[[0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "cat_dict = {\n",
    "    \"Jungle\": 0,\n",
    "    \"Top\": 1,\n",
    "    \"Chest\": 2,\n",
    "    \"Signature\": 3,\n",
    "    \"Thump\": 4,\n",
    "    \"Vinyl\": 5,\n",
    "    \"Stomp\": 6,\n",
    "    \"Punchy\": 7,\n",
    "    \"808s\": 8,\n",
    "    \"Distorted\": 9,\n",
    "    \"Psy\": 10,\n",
    "    \"Big\": 11,\n",
    "    \"Hardstyle\": 12,\n",
    "    \"Stadium\": 13,\n",
    "}\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.05, random_state=42)\n",
    "\n",
    "y_train = list(map(cat_dict.get, y_train))\n",
    "y_val = list(map(cat_dict.get, y_val))\n",
    "print(y_val)\n",
    "\n",
    "y_train_cat = to_categorical(y_train, num_classes)\n",
    "y_val_cat = to_categorical(y_val, num_classes)\n",
    "\n",
    "print(y_train_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# 将X_train和X_val转换为RaggedTensor\n",
    "X_train_ragged = tf.ragged.constant(X_train)\n",
    "X_val_ragged = tf.ragged.constant(X_val)\n",
    "y_train_cat = tf.convert_to_tensor(y_train_cat)\n",
    "y_val_cat = tf.convert_to_tensor(y_val_cat)\n",
    "\n",
    "# 创建tf.data.Dataset\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train_ragged, y_train_cat))\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((X_val_ragged, y_val_cat))\n",
    "\n",
    "# 批量化数据\n",
    "batch_size = 32\n",
    "train_dataset = train_dataset.batch(batch_size)\n",
    "val_dataset = val_dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "11/11 [==============================] - 1s 122ms/step - loss: 0.2817 - accuracy: 0.9286 - val_loss: 1.0228 - val_accuracy: 0.7778\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 1s 115ms/step - loss: 0.3012 - accuracy: 0.8988 - val_loss: 1.0323 - val_accuracy: 0.8333\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 1s 114ms/step - loss: 0.2793 - accuracy: 0.9077 - val_loss: 1.1641 - val_accuracy: 0.7778\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 1s 119ms/step - loss: 0.2317 - accuracy: 0.9315 - val_loss: 1.1224 - val_accuracy: 0.7222\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 1s 115ms/step - loss: 0.1966 - accuracy: 0.9464 - val_loss: 1.1287 - val_accuracy: 0.7222\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 1s 118ms/step - loss: 0.1898 - accuracy: 0.9494 - val_loss: 1.0021 - val_accuracy: 0.7778\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 1s 123ms/step - loss: 0.2140 - accuracy: 0.9286 - val_loss: 0.9263 - val_accuracy: 0.7778\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 1s 122ms/step - loss: 0.1445 - accuracy: 0.9643 - val_loss: 0.9903 - val_accuracy: 0.8333\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 1s 122ms/step - loss: 0.1529 - accuracy: 0.9732 - val_loss: 0.8804 - val_accuracy: 0.8333\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 1s 119ms/step - loss: 0.1502 - accuracy: 0.9613 - val_loss: 0.8535 - val_accuracy: 0.8333\n"
     ]
    }
   ],
   "source": [
    "# 训练模型\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=10,\n",
    "    validation_data=val_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 通过新的数据集验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 52ms/step\n",
      "Validation Accuracy: 58.62%\n"
     ]
    }
   ],
   "source": [
    "# 使用模型进行预测\n",
    "predictions = model.predict(val_dataset)\n",
    "\n",
    "# 转换预测结果为类别索引\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "# 由于验证标签已经是类别索引，直接使用\n",
    "true_classes = y_val\n",
    "\n",
    "# 计算准确率\n",
    "accuracy = np.mean(predicted_classes == true_classes)\n",
    "print(f\"Validation Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 保存训练好的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to test_kick_1.h5\n"
     ]
    }
   ],
   "source": [
    "# 假设 filepath 是你想要保存模型的路径\n",
    "filepath = 'test_kick_1.h5'\n",
    "# 保存模型\n",
    "model.save(filepath)\n",
    "\n",
    "# 检查模型文件是否存在\n",
    "if os.path.exists(filepath):\n",
    "    print(f\"Model saved to {filepath}\")\n",
    "else:\n",
    "    print(f\"Model save failed. File not found at {filepath}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
